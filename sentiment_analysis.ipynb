{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\"\"\"\n",
    "sentiment_analysis.py\n",
    "\n",
    "Sentiment analysis using:\n",
    " - TextBlob (polarity)\n",
    " - VADER (compound score)\n",
    " - Transformers (DistilBERT fine-tuned on SST-2)\n",
    "\n",
    "Features:\n",
    " - Text cleaning (lowercase, remove punctuation & numbers)\n",
    " - Compute scores from all three methods (numeric)\n",
    " - Map transformer labels to numeric scores\n",
    " - Visualize distributions and save results\n",
    "\n",
    "Run:\n",
    " 1) Install dependencies:\n",
    "    pip install pandas numpy matplotlib seaborn textblob vaderSentiment transformers torch nltk\n",
    "\n",
    " 2) For VADER lexicon and TextBlob corpora (run once):\n",
    "    python -c \"import nltk; nltk.download('vader_lexicon')\"\n",
    "    python -m textblob.download_corpora\n",
    "\n",
    " 3) Run the script:\n",
    "    python sentiment_analysis.py\n",
    "\"\"\"\n",
    "\n",
    "# --- Imports ---\n",
    "import re                       # regular expressions, used for text cleaning\n",
    "import pandas as pd             # tabular data handling\n",
    "import numpy as np              # numeric operations\n",
    "import matplotlib.pyplot as plt # plotting\n",
    "import seaborn as sns           # nicer statistical plots\n",
    "import warnings                 # to show or ignore warnings\n",
    "\n",
    "# NLP libraries\n",
    "from textblob import TextBlob\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# transformers pipeline for DistilBERT. We'll try to import it,\n",
    "# but if it's not available or model download fails we will gracefully skip it.\n",
    "try:\n",
    "    from transformers import pipeline\n",
    "    TRANSFORMERS_AVAILABLE = True\n",
    "except Exception:\n",
    "    TRANSFORMERS_AVAILABLE = False\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")  # keep the output clean for educational runs\n",
    "\n",
    "# --- Preprocessing function ---\n",
    "def clean_text(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Clean the input text:\n",
    "     - convert to string (protect against NaN)\n",
    "     - lowercase\n",
    "     - remove URLs\n",
    "     - remove punctuation and numbers (keep only letters and spaces)\n",
    "     - collapse multiple spaces\n",
    "     - strip leading/trailing spaces\n",
    "    \"\"\"\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    # ensure it's a string\n",
    "    s = str(text)\n",
    "    # lowercase\n",
    "    s = s.lower()\n",
    "    # remove URLs (common in social media)\n",
    "    s = re.sub(r'http\\S+|www\\.\\S+', '', s)\n",
    "    # remove non-letter characters (this removes punctuation and numbers)\n",
    "    # [^a-z\\s] -> anything that's not a lowercase letter or space\n",
    "    s = re.sub(r'[^a-z\\s]', ' ', s)\n",
    "    # collapse multiple spaces to single space\n",
    "    s = re.sub(r'\\s+', ' ', s).strip()\n",
    "    return s\n",
    "\n",
    "# --- Scoring wrappers ---\n",
    "# TextBlob returns polarity in [-1, 1] where negative -> negative sentiment,\n",
    "# positive -> positive sentiment and 0 -> neutral.\n",
    "def textblob_score(text: str) -> float:\n",
    "    tb = TextBlob(text)\n",
    "    return tb.sentiment.polarity  # float in [-1.0, +1.0]\n",
    "\n",
    "# VADER returns a dict of scores; 'compound' is a normalized, weighted composite in [-1, 1].\n",
    "vader_analyzer = SentimentIntensityAnalyzer()\n",
    "def vader_compound_score(text: str) -> float:\n",
    "    return vader_analyzer.polarity_scores(text)[\"compound\"]\n",
    "\n",
    "# DistilBERT pipeline returns {'label': 'POSITIVE'/'NEGATIVE', 'score': prob}\n",
    "# We'll map it to a numeric in [-1, 1] by:\n",
    "#   numeric = score  if label == POSITIVE (range [0.5,1.0] typically)\n",
    "#   numeric = -score if label == NEGATIVE\n",
    "# This preserves both direction and confidence.\n",
    "distilbert_pipe = None\n",
    "if TRANSFORMERS_AVAILABLE:\n",
    "    try:\n",
    "        # model is 'distilbert-base-uncased-finetuned-sst-2-english' by default for sentiment-analysis\n",
    "        distilbert_pipe = pipeline(\"sentiment-analysis\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "    except Exception as e:\n",
    "        # e.g., no internet or torch not available; we'll continue but skip transformer step later\n",
    "        print(\"Warning: transformers pipeline could not be initialized. DistilBERT will be skipped.\")\n",
    "        distilbert_pipe = None\n",
    "\n",
    "def distilbert_score(text: str) -> float:\n",
    "    \"\"\"\n",
    "    Returns a numeric score in [-1, 1] derived from the transformer label+score.\n",
    "    If transformer pipeline isn't available, returns np.nan.\n",
    "    \"\"\"\n",
    "    if distilbert_pipe is None:\n",
    "        return np.nan\n",
    "    # run the pipeline on the single text\n",
    "    res = distilbert_pipe(text[:512])  # limit to 512 chars/tokens to be safe\n",
    "    # pipeline returns a list of dicts for single input\n",
    "    if isinstance(res, list) and len(res) > 0:\n",
    "        r = res[0]\n",
    "        label = r.get(\"label\", \"\")\n",
    "        score = float(r.get(\"score\", 0.0))\n",
    "        if label.upper().startswith(\"POS\"):\n",
    "            return score  # positive mapped to +score\n",
    "        else:\n",
    "            return -score  # negative mapped to -score\n",
    "    return np.nan\n",
    "\n",
    "# --- Label helpers (human-readable categories) ---\n",
    "def label_from_score(score: float, method: str = \"generic\") -> str:\n",
    "    \"\"\"\n",
    "    Map numeric score to 'positive' / 'negative' / 'neutral' with reasonable thresholds.\n",
    "    method:\n",
    "      - \"vader\": uses VADER common thresholds (+0.05, -0.05)\n",
    "      - \"generic\": uses 0 as boundary (<=0 negative, ==0 neutral, >0 positive)\n",
    "    \"\"\"\n",
    "    if pd.isna(score):\n",
    "        return \"unknown\"\n",
    "    if method == \"vader\":\n",
    "        if score >= 0.05:\n",
    "            return \"positive\"\n",
    "        elif score <= -0.05:\n",
    "            return \"negative\"\n",
    "        else:\n",
    "            return \"neutral\"\n",
    "    else:\n",
    "        # generic: treat exactly 0 as neutral\n",
    "        if score > 0:\n",
    "            return \"positive\"\n",
    "        elif score < 0:\n",
    "            return \"negative\"\n",
    "        else:\n",
    "            return \"neutral\"\n",
    "\n",
    "# --- Main pipeline function ---\n",
    "def analyze_texts(texts):\n",
    "    \"\"\"\n",
    "    texts: list-like of raw text strings\n",
    "    returns: pandas.DataFrame with original, cleaned, 3 scores, labels, average\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame({\"text\": list(texts)})\n",
    "    # clean the text\n",
    "    df[\"clean_text\"] = df[\"text\"].apply(clean_text)\n",
    "\n",
    "    # compute TextBlob polarity\n",
    "    df[\"textblob_score\"] = df[\"clean_text\"].apply(textblob_score)\n",
    "\n",
    "    # compute VADER compound\n",
    "    df[\"vader_compound\"] = df[\"clean_text\"].apply(vader_compound_score)\n",
    "\n",
    "    # compute DistilBERT numeric score if available\n",
    "    if distilbert_pipe is not None:\n",
    "        # batching is more efficient than per-row calls; pipeline supports list input.\n",
    "        clean_texts = df[\"clean_text\"].tolist()\n",
    "        # run pipeline on the batch\n",
    "        try:\n",
    "            results = distilbert_pipe(clean_texts, truncation=True)\n",
    "            # results is a list of dicts: map them to numeric scores\n",
    "            df[\"distilbert_label\"] = [r.get(\"label\", \"\") for r in results]\n",
    "            df[\"distilbert_prob\"] = [r.get(\"score\", np.nan) for r in results]\n",
    "            df[\"distilbert_score\"] = [\n",
    "                (prob if lbl.upper().startswith(\"POS\") else -prob) if (isinstance(prob, (int, float)) and lbl) else np.nan\n",
    "                for lbl, prob in zip(df[\"distilbert_label\"], df[\"distilbert_prob\"])\n",
    "            ]\n",
    "        except Exception:\n",
    "            # If batch fails, fall back to per-row safe call (slower)\n",
    "            df[\"distilbert_score\"] = df[\"clean_text\"].apply(distilbert_score)\n",
    "            df[\"distilbert_label\"] = df[\"clean_text\"].apply(\n",
    "                lambda t: distilbert_pipe(t[:512])[0][\"label\"] if distilbert_pipe is not None else \"unknown\")\n",
    "            df[\"distilbert_prob\"] = df[\"clean_text\"].apply(\n",
    "                lambda t: distilbert_pipe(t[:512])[0][\"score\"] if distilbert_pipe is not None else np.nan)\n",
    "    else:\n",
    "        # mark these columns as missing\n",
    "        df[\"distilbert_score\"] = np.nan\n",
    "        df[\"distilbert_label\"] = \"skipped\"\n",
    "        df[\"distilbert_prob\"] = np.nan\n",
    "\n",
    "    # human-readable labels\n",
    "    df[\"textblob_label\"] = df[\"textblob_score\"].apply(lambda s: label_from_score(s, method=\"generic\"))\n",
    "    df[\"vader_label\"] = df[\"vader_compound\"].apply(lambda s: label_from_score(s, method=\"vader\"))\n",
    "    df[\"distilbert_label_readable\"] = df[\"distilbert_score\"].apply(lambda s: label_from_score(s, method=\"generic\")\n",
    "                                                                    if not pd.isna(s) else \"unknown\")\n",
    "\n",
    "    # average numeric score across available methods (skip nan)\n",
    "    df[\"avg_sentiment\"] = df[[\"textblob_score\", \"vader_compound\", \"distilbert_score\"]].mean(axis=1, skipna=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "# --- Visualization helpers ---\n",
    "def plot_distributions(df):\n",
    "    \"\"\"\n",
    "    Several small plots to compare how the three methods distribute labels & scores.\n",
    "    \"\"\"\n",
    "    sns.set(style=\"whitegrid\")\n",
    "    plt.figure(figsize=(14, 10))\n",
    "\n",
    "    # 1) Count plot: TextBlob labels\n",
    "    plt.subplot(2, 2, 1)\n",
    "    sns.countplot(x=\"textblob_label\", data=df, order=[\"positive\", \"neutral\", \"negative\"])\n",
    "    plt.title(\"TextBlob label counts\")\n",
    "\n",
    "    # 2) Count plot: VADER labels\n",
    "    plt.subplot(2, 2, 2)\n",
    "    sns.countplot(x=\"vader_label\", data=df, order=[\"positive\", \"neutral\", \"negative\"])\n",
    "    plt.title(\"VADER label counts\")\n",
    "\n",
    "    # 3) Bar plot: DistilBERT label counts (if available)\n",
    "    plt.subplot(2, 2, 3)\n",
    "    if \"distilbert_label\" in df.columns and df[\"distilbert_label\"].nunique() > 0:\n",
    "        sns.countplot(x=\"distilbert_label\", data=df)\n",
    "        plt.title(\"DistilBERT label counts (raw)\")\n",
    "    else:\n",
    "        plt.text(0.5, 0.5, \"DistilBERT skipped or unavailable\", ha='center', va='center')\n",
    "        plt.title(\"DistilBERT\")\n",
    "\n",
    "    # 4) Histogram: average sentiment numeric\n",
    "    plt.subplot(2, 2, 4)\n",
    "    sns.histplot(df[\"avg_sentiment\"].dropna(), kde=True, bins=20)\n",
    "    plt.title(\"Histogram of average sentiment score\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def correlation_report(df):\n",
    "    \"\"\"\n",
    "    Print correlations between the numeric scores of the three methods.\n",
    "    Useful to know how aligned they are.\n",
    "    \"\"\"\n",
    "    cols = [\"textblob_score\", \"vader_compound\", \"distilbert_score\"]\n",
    "    present = [c for c in cols if c in df.columns]\n",
    "    if len(present) < 2:\n",
    "        print(\"Not enough score columns to compute correlation.\")\n",
    "        return\n",
    "    print(\"\\nCorrelation matrix between numeric scores:\")\n",
    "    print(df[present].corr())\n",
    "\n",
    "# --- Example / main execution ---\n",
    "if __name__ == \"__main__\":\n",
    "    # Example texts - replace these with reading a CSV file if you have one\n",
    "    sample_texts = [\n",
    "        \"I love this product! It's fantastic and works amazingly well.\",\n",
    "        \"This is the worst service I've ever experienced. Totally unacceptable.\",\n",
    "        \"Not bad, but could be better.\",\n",
    "        \"I'm not sure how I feel about this.\",\n",
    "        \"Absolutely brilliant performance by the cast!\",\n",
    "        \"The item arrived broken. Very disappointed.\",\n",
    "        \"\"  # empty string edge case\n",
    "    ]\n",
    "\n",
    "    # Or uncomment to read from a CSV file with a 'text' column:\n",
    "    # df_input = pd.read_csv(\"your_file.csv\")  # ensure 'text' column exists\n",
    "    # sample_texts = df_input['text'].tolist()\n",
    "\n",
    "    print(\"Cleaning + analyzing texts...\")\n",
    "    results_df = analyze_texts(sample_texts)\n",
    "\n",
    "    # show results\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    print(\"\\nResults (first rows):\")\n",
    "    print(results_df.head(20))\n",
    "\n",
    "    # save results\n",
    "    results_df.to_csv(\"sentiment_results.csv\", index=False)\n",
    "    print(\"\\nSaved results to sentiment_results.csv\")\n",
    "\n",
    "    # visualizations\n",
    "    plot_distributions(results_df)\n",
    "\n",
    "    # correlation\n",
    "    correlation_report(results_df)\n",
    "\n",
    "    print(\"\\nDone. If DistilBERT was skipped, install torch and transformers, then rerun.\")\n"
   ],
   "id": "ce07bd958ef47062"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
